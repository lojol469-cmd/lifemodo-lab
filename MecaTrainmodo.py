# Copyright (c) 2025 Belikan. All rights reserved.
# Licensed under the LifeModo AI Lab License. See LICENSE file for details.
# Contact: belikan@lifemodo.ai

# ‚úÖ Installer les d√©pendances YOLOv11
!pip install -U ultralytics easyocr ray[tune] albumentations --quiet

# === √âtape 1 : Monter Google Drive ===
from google.colab import drive
import os, sys, shutil, random, re, torch, cv2, easyocr
import numpy as np
from ultralytics import YOLO
import matplotlib.pyplot as plt
from PIL import Image
import albumentations as A
from ray import tune
drive.mount('/content/drive')

# === Configuration du Projet ===
PROJECT_DIR = '/content/drive/MyDrive/mechanical_dataset'
RAW_DIR = os.path.join(PROJECT_DIR, 'images_raw')
DATASET_DIR = os.path.join(PROJECT_DIR, 'dataset')
os.makedirs(RAW_DIR, exist_ok=True)
os.makedirs(DATASET_DIR, exist_ok=True)
os.makedirs(os.path.join(PROJECT_DIR, 'reports'), exist_ok=True)  # Nouveau: dossier pour rapports

# Nouvelle fonctionnalit√© 1: Support pour vid√©os raw
VIDEO_DIR = os.path.join(PROJECT_DIR, 'videos_raw')
os.makedirs(VIDEO_DIR, exist_ok=True)

# Nouvelle fonctionnalit√© 2: Int√©gration LLM placeholder (utilise Grok API ou similaire)
def llm_label_suggestion(image_path):
    # Placeholder: Appel √† un LLM pour suggestions de labels
    # Ex: response = requests.post("https://api.x.ai/v1/chat/completions", ...)
    return "suggested_label_from_llm"  # Remplacer par vrai appel

# === Fonction pour calculer l'ID du prochain mod√®le ===
def get_next_model_version(base_dir, base_name="yolov11_finetuned_v"):
    existing = [d for d in os.listdir(base_dir) if d.startswith(base_name)]
    versions = [int(re.findall(r'\d+', name)[0]) for name in existing if re.findall(r'\d+', name)]
    return max(versions, default=0) + 1

def new_images_detected(train_dir, raw_dir):
    trained_images = set(os.listdir(train_dir))
    raw_images = set(os.listdir(raw_dir))
    new_images = raw_images - trained_images
    return len(new_images) > 0

if new_images_detected(os.path.join(DATASET_DIR, 'images/train'), RAW_DIR):
    MODEL_VERSION = get_next_model_version(PROJECT_DIR)
    MODEL_NAME = f"yolov11_finetuned_v{MODEL_VERSION}"
    print(f"üìå Nouvelles images d√©tect√©es. Nouveau mod√®le : {MODEL_NAME}")
else:
    print("‚úÖ Aucune nouvelle image d√©tect√©e. Pas de nouveau mod√®le.")
    sys.exit()

# === √âtape 2 : Installer les d√©pendances suppl√©mentaires ===
!pip install -q easyocr opencv-python-headless ultralytics ray[tune] albumentations reportlab
!apt-get -qq install -y tesseract-ocr tesseract-ocr-fra libtesseract-dev

# === √âtape 3 : Imports suppl√©mentaires ===
from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas
import easyocr

# Nouvelle fonctionnalit√© 3: Lecteur OCR am√©lior√© avec EasyOCR
reader = easyocr.Reader(['fr', 'en'])

# === √âtape 4 : Lister les images et vid√©os ===
imgs = sorted([f for f in os.listdir(RAW_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
videos = sorted([f for f in os.listdir(VIDEO_DIR) if f.lower().endswith(('.mp4', '.avi'))])
if not imgs and not videos:
    sys.exit("‚ùå Aucune image ou vid√©o trouv√©e.")
print(f"üì∏ {len(imgs)} images et {len(videos)} vid√©os trouv√©es.")

# Nouvelle fonctionnalit√© 4: Extraction de frames des vid√©os pour augmentation dataset
def extract_frames(video_path, output_dir, frame_rate=1):
    cap = cv2.VideoCapture(video_path)
    count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if ret and count % frame_rate == 0:
            cv2.imwrite(os.path.join(output_dir, f"frame_{count}.jpg"), frame)
        count += 1
    cap.release()

for vid in videos:
    extract_frames(os.path.join(VIDEO_DIR, vid), RAW_DIR)

# === √âtape 5 : D√©tection dynamique des classes avec OCR am√©lior√© et LLM ===
labels_set = set()
for img_name in imgs:
    img_path = os.path.join(RAW_DIR, img_name)
    result = reader.readtext(img_path)
    txt = ' '.join([det[1] for det in result]).lower().strip()
    fname_label = img_name.lower().split('_')[0].split('.')[0]
    llm_suggest = llm_label_suggestion(img_path)
    candidate = txt or fname_label or llm_suggest
    if candidate:
        label = candidate.strip().split()[0]
        labels_set.add(label)

classes = sorted(labels_set)
print(f"‚úÖ {len(classes)} classes d√©tect√©es : {classes}")

# === √âtape 6 : Pr√©parer les dossiers avec support segmentation ===
for split in ['images/train', 'images/val', 'labels/train', 'labels/val', 'masks/train', 'masks/val']:
    os.makedirs(os.path.join(DATASET_DIR, split), exist_ok=True)

# Nouvelle fonctionnalit√© 5: Augmentation de donn√©es avec Albumentations
transform = A.Compose([
    A.RandomRotate90(),
    A.Flip(),
    A.Transpose(),
    A.GaussNoise(),
    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),
    A.Blur(blur_limit=3),
    A.OpticalDistortion(),
    A.GridDistortion(),
])

def augment_image(img_path, output_dir, num_augs=3):
    image = cv2.imread(img_path)
    for i in range(num_augs):
        augmented = transform(image=image)['image']
        cv2.imwrite(os.path.join(output_dir, f"aug_{i}_{os.path.basename(img_path)}"), augmented)

# Appliquer augmentation
for img_name in imgs:
    augment_image(os.path.join(RAW_DIR, img_name), RAW_DIR)

# Mise √† jour liste images apr√®s augmentation
imgs = sorted([f for f in os.listdir(RAW_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])

# === √âtape 7 : G√©n√©ration des annotations YOLO avec segmentation ===
from ultralytics.models.sam import SAM  # Nouvelle fonctionnalit√© 6: Utilisation de SAM pour masques
sam_model = SAM('sam2_b.pt')

MIN_CONTOUR_AREA = 500
for img_name in imgs:
    img_path = os.path.join(RAW_DIR, img_name)
    img = cv2.imread(img_path)
    result = reader.readtext(img_path)
    txt = ' '.join([det[1] for det in result]).lower().strip()
    fname_label = img_name.lower().split('_')[0].split('.')[0]
    candidate = txt if len(txt) > len(fname_label) else fname_label
    label = candidate.strip().split()[0]

    if label not in classes:
        classes.append(label)
        classes = sorted(set(classes))
        print(f"‚ûï Nouveau label d√©tect√© : {label}")

    label_id = classes.index(label)
    # D√©tection contours pour bbox
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    _, th = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    contours, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    h, w = img.shape[:2]
    bboxes = []
    for cnt in contours:
        x, y, wi, hi = cv2.boundingRect(cnt)
        if wi * hi >= MIN_CONTOUR_AREA:
            bboxes.append((label_id, (x + wi / 2) / w, (y + hi / 2) / h, wi / w, hi / h))

    if not bboxes:
        bboxes = [(label_id, 0.5, 0.5, 1.0, 1.0)]

    label_path = os.path.join(DATASET_DIR, 'labels/train', img_name.rsplit('.', 1)[0] + '.txt')
    with open(label_path, 'w') as f:
        for b in bboxes:
            f.write(f"{b[0]} {b[1]:.6f} {b[2]:.6f} {b[3]:.6f} {b[4]:.6f}\n")

    # G√©n√©ration masques avec SAM
    sam_results = sam_model(img_path)
    mask_path = os.path.join(DATASET_DIR, 'masks/train', img_name.rsplit('.', 1)[0] + '.png')
    # Sauvegarde masque (simplifi√©)
    cv2.imwrite(mask_path, sam_results[0].masks.data[0].cpu().numpy() * 255)

    shutil.copy(img_path, os.path.join(DATASET_DIR, 'images/train', img_name))

print("‚úÖ Annotations YOLO et masques cr√©√©s.")

# === √âtape 8 : S√©parer train / val (80/20) avec masques ===
train_imgs = os.listdir(os.path.join(DATASET_DIR, 'images/train'))
random.shuffle(train_imgs)
split_idx = int(0.8 * len(train_imgs))
for img_name in train_imgs[split_idx:]:
    shutil.move(os.path.join(DATASET_DIR, 'images/train', img_name),
                os.path.join(DATASET_DIR, 'images/val', img_name))
    txt_name = img_name.rsplit('.', 1)[0] + '.txt'
    mask_name = img_name.rsplit('.', 1)[0] + '.png'
    if os.path.exists(os.path.join(DATASET_DIR, 'labels/train', txt_name)):
        shutil.move(os.path.join(DATASET_DIR, 'labels/train', txt_name),
                    os.path.join(DATASET_DIR, 'labels/val', txt_name))
    if os.path.exists(os.path.join(DATASET_DIR, 'masks/train', mask_name)):
        shutil.move(os.path.join(DATASET_DIR, 'masks/train', mask_name),
                    os.path.join(DATASET_DIR, 'masks/val', mask_name))

print(f"üìÇ Donn√©es s√©par√©es : {split_idx} train / {len(train_imgs) - split_idx} val")

# === √âtape 9 : Cr√©er data.yaml avec support segmentation ===
yaml_path = os.path.join(PROJECT_DIR, 'data.yaml')
with open(yaml_path, 'w') as f:
    f.write(f"train: {DATASET_DIR}/images/train\n")
    f.write(f"val: {DATASET_DIR}/images/val\n")
    f.write(f"nc: {len(classes)}\n")
    f.write(f"names: {classes}\n")
    f.write("segment: true\n")  # Activation segmentation
print(f"üìÑ data.yaml cr√©√© : {yaml_path}")

# Nouvelle fonctionnalit√© 7: Hyperparameter tuning avec Ray Tune
def train_fn(config):
    model = YOLO("yolov11n.pt")  # Utilise YOLOv11
    model.train(data=yaml_path, epochs=config["epochs"], imgsz=config["imgsz"], batch=config["batch"])

search_space = {
    "epochs": tune.choice([20, 30, 50]),
    "imgsz": tune.choice([640, 800]),
    "batch": tune.choice([4, 8, 16]),
}
analysis = tune.run(train_fn, config=search_space, num_samples=5)

best_config = analysis.get_best_config(metric="metrics/mAP50-95(B)", mode="max")
print(f"Meilleure config: {best_config}")

# === √âtape 10 : Fine-tuning avec YOLOv11 et meilleure config ===
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"‚öôÔ∏è Entra√Ænement sur device : {device}")

base_model_path = os.path.join(PROJECT_DIR, "yolov11_model", "weights", "best.pt")
if not os.path.exists(base_model_path):
    base_model_path = "yolov11n.pt"  # YOLOv11 nano pour start

model = YOLO(base_model_path)
results = model.train(
    data=yaml_path,
    epochs=best_config["epochs"],
    imgsz=best_config["imgsz"],
    batch=best_config["batch"],
    device=0 if device == 'cuda' else 'cpu',
    project=PROJECT_DIR,
    name=MODEL_NAME,
    exist_ok=True,
    resume=False,
    save=True,
    verbose=True,
    val=True,
    augment=True,  # Augmentation int√©gr√©e
    mosaic=1.0,
    mixup=0.1,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=10.0,
    translate=0.1,
    scale=0.5,
    shear=2.0,
    perspective=0.0,
    flipud=0.5,
    fliplr=0.5,
    bgr=0.0,
    erasing=0.4,
    crop_fraction=1.0
)

print(f"‚úÖ Fine-tuning termin√©. Nouveau mod√®le : {MODEL_NAME}")

# Nouvelle fonctionnalit√© 8: Export √† ONNX pour d√©ploiement
model.export(format="onnx", dynamic=True)
print("üì¶ Mod√®le export√© en ONNX.")

# === √âtape 11 : Tester sur une image avec anomaly detection ===
trained_model_path = os.path.join(PROJECT_DIR, MODEL_NAME, "weights", "best.pt")
trained_model = YOLO(trained_model_path)
test_image_path = os.path.join(RAW_DIR, imgs[0])
results = trained_model(test_image_path, conf=0.25)

# Nouvelle fonctionnalit√© 9: D√©tection d'anomalies basique (e.g., low conf = anomaly)
anomalies = [box for box in results[0].boxes if box.conf < 0.3]

res_plotted = results[0].plot()
plt.figure(figsize=(10, 10))
plt.imshow(res_plotted)
plt.axis('off')
plt.title(f"üìç R√©sultat - {MODEL_NAME}")
plt.show()

# Nouvelle fonctionnalit√© 10: G√©n√©ration de rapport PDF
def generate_report(pdf_path, results, anomalies):
    c = canvas.Canvas(pdf_path, pagesize=letter)
    c.drawString(100, 750, "Rapport d'Inspection M√©canique")
    c.drawString(100, 730, f"Mod√®le: {MODEL_NAME}")
    c.drawString(100, 710, f"D√©tections: {len(results[0].boxes)}")
    if anomalies:
        c.drawString(100, 690, "Anomalies d√©tect√©es!")
    c.save()

report_path = os.path.join(PROJECT_DIR, 'reports', f"report_{MODEL_NAME}.pdf")
generate_report(report_path, results, anomalies)
print(f"üìë Rapport g√©n√©r√© : {report_path}")

# Nouvelle fonctionnalit√© 11: Support multi-GPU
if torch.cuda.device_count() > 1:
    model = torch.nn.DataParallel(model)

# Nouvelle fonctionnalit√© 12: Ensemble de mod√®les (simplifi√©)
previous_models = [os.path.join(PROJECT_DIR, d, "weights", "best.pt") for d in os.listdir(PROJECT_DIR) if d.startswith("yolov11_finetuned_v")]
ensemble_results = []
for pm in previous_models[:2]:  # 2 mod√®les pour ensemble
    em = YOLO(pm)
    ensemble_results.append(em(test_image_path))

# Moyenne des r√©sultats (simplifi√©)
print("Ensemble r√©sultats calcul√©s.")

# === √âtape Finale : Lister les mod√®les fine-tun√©s ===
def list_available_models(base_dir, base_name="yolov11_finetuned_v"):
    print("\nüìö Mod√®les disponibles :")
    models = sorted([d for d in os.listdir(base_dir) if d.startswith(base_name)])
    if not models:
        print("‚ùå Aucun mod√®le trouv√©.")
    else:
        for idx, model_dir in enumerate(models, 1):
            model_path = os.path.join(base_dir, model_dir, "weights", "best.pt")
            status = "‚úÖ Pr√™t" if os.path.exists(model_path) else "‚õî Incomplet"
            print(f"{idx}. {model_dir} ‚Üí {status}")

list_available_models(PROJECT_DIR)